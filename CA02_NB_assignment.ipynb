{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCZYXwtCsL_y"
   },
   "source": [
    "CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm. \n",
    "\n",
    "In this assignment you will ...\n",
    "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
    "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
    "\n",
    "IMPORTANT NOTE:\n",
    "\n",
    "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4p_DvtT7sOIr",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Import all other necessary libraries. Your code below ...\n",
    "#\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Our make_Dictionary function takes in all of your emails and creates a dictionary for the 3000 most-common words within those emails*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jjKF0nIMwz8_",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_Dictionary(root_dir):\n",
    "  all_words = []\n",
    "  #emails is the list of all filepaths in the root_directory\n",
    "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
    "  for mail in emails:\n",
    "    #we want to go through each line of an email and separate it into single words\n",
    "    with open(mail) as m:\n",
    "      for line in m:\n",
    "        words = line.split()\n",
    "        all_words += words\n",
    "  #the counter counts how many times each word appears in all_words and then creates the dictionary\n",
    "  dictionary = Counter(all_words)\n",
    "  list_to_remove = list(dictionary)\n",
    " # we need to remove items from the dictionary that are not alphabetic because we only want words\n",
    "  for item in list_to_remove:\n",
    "  \n",
    "    if item.isalpha() == False:\n",
    "      del dictionary[item]\n",
    "    elif len(item) == 1:\n",
    "      del dictionary[item]\n",
    "  # we only care about the 3000 most common words\n",
    "  dictionary = dictionary.most_common(3000)\n",
    "  return dictionary\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Our extract_features function will go through all the files in the directory and break up each document line by line, go through each word of each line and count how many times that word shows up in the document. This becomes our features_matrix, and then it checks the name of the file to determine which documents are spam and saves that information to the train_labels array*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dmVW5xNlyOFc",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(mail_dir):\n",
    "  #files is the list of all emails within a directory for ex : 'train-mails/spmsga62.txt'\n",
    "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
    "  #create blank features matrix and a blank labels array\n",
    "  features_matrix = np.zeros((len(files),3000))\n",
    "  train_labels = np.zeros(len(files))\n",
    "  count = 1;\n",
    "  #docID tells us which number doc we're on within files\n",
    "  docID = 0;\n",
    "  for fil in files:\n",
    "    with open(fil) as fi:\n",
    "      #iterate over the lines in fi [which is a txt file]\n",
    "      for i, line in enumerate(fi):\n",
    "         # the content of the email starts on the third line \n",
    "        if i ==2:\n",
    "          #split up the line by space so that we get the words\n",
    "          words = line.split()\n",
    "          #we need to go through all the words in fi and check if they show up in our dictionary\n",
    "          for word in words:\n",
    "            wordID = 0\n",
    "            #i is the index of dictionary, d is the word in dictionary\n",
    "            for i, d in enumerate(dictionary):\n",
    "              if d[0] == word:\n",
    "                wordID = i #saves the index where you found the word\n",
    "                #now we go back to our features matrix and add how many times a given word shows up in our docID\n",
    "                features_matrix[docID,wordID] = words.count(word)\n",
    "      train_labels[docID] = 0; #label the docID as 0 [i.e not spam]\n",
    "      filepathTokens = fil.split('/')\n",
    "      #grab the last part of the path of the document\n",
    "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
    "      if lastToken.startswith(\"spmsg\"):\n",
    "        #if the txt file starts with \"spmsg\" then we label it as a spam message [encoded with a 1]\n",
    "        train_labels[docID] = 1;\n",
    "        count = count + 1 # we increase the count of spam messages that we've found\n",
    "      #at the end of the loop regardless if the docID is spam or not we update the docID to look at the next doc\n",
    "      docID = docID + 1 \n",
    "  return features_matrix, train_labels                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zoq-rE7Mx0pp",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Enter the \"path\" of your \"train_mails\" and \"test-mails\" FOLDERS in this cell ...\n",
    "# for example: TRAIN_DIR = '../../train-mails'\n",
    "#              TEST_DIR = '../../test-mails'\n",
    "TRAIN_DIR = 'Data/train-mails'\n",
    "TEST_DIR = 'Data/test-mails'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n"
     ]
    }
   ],
   "source": [
    "dictionary = make_Dictionary(TRAIN_DIR)\n",
    "\n",
    "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
    "features_matrix, labels = extract_features(TRAIN_DIR)\n",
    "test_features_matrix, test_labels = extract_features(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model using Gaussian Naive Bayes algorithm...\n",
      "\n",
      "Training completed \n",
      "\n",
      "testing trained model to predict Test Data labels\n",
      "\n",
      "Completed classification of the Test Data.. now printing Accuracy Score by comparing the Predicted Labels with the Test Labels: \n",
      "\n",
      "Accuracy: 0.9653846154\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(features_matrix, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(features_matrix, labels)\n",
    "print(\"Training model using Gaussian Naive Bayes algorithm...\\n\")\n",
    "print(\"Training completed \\n\")\n",
    "\n",
    "y_pred = gnb.predict(test_features_matrix)\n",
    "print(\"testing trained model to predict Test Data labels\\n\")\n",
    "\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "print(\"Completed classification of the Test Data.. now printing Accuracy Score by comparing the Predicted Labels with the Test Labels: \\n\")\n",
    "print(f\"Accuracy: {accuracy:.10f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n",
      "Training Model using Gaussian Naibe Bayes algorithm .....\n",
      "Training completed\n",
      "testing trained model to predict Test Data labels\n",
      "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
      "0.9653846153846154\n"
     ]
    }
   ],
   "source": [
    "# In this section enter your code to TRAIN the model using Naive Bayes algorithm, then PREDICT and then evaluate PERFORMANCE (Accuracy)\n",
    "# Your code below ...\n",
    "#\n",
    "#\n",
    "#\n",
    "# Your output should look like below if your code is right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5_mPrvN586A"
   },
   "source": [
    "======================= END OF PROGRAM ========================="
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOaSi3qlFUlqTup/1esXCKD",
   "collapsed_sections": [],
   "name": "naive_bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
